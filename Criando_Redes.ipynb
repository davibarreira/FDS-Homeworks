{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RendererRegistry.enable('notebook')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import altair as alt\n",
    "alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 'Sequential Monte Carlo samplers for capital allocation under copula-dependent risk models']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = []\n",
    "authors = []\n",
    "conn = sqlite3.connect(DATABASE,timeout=10)\n",
    "for row in conn.execute('SELECT * FROM paper'):\n",
    "    papers.append({'id':row[0],'paper_name':row[1]})\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE = 'hw1_test.sqlite'\n",
    "\n",
    "def Select_All(db,table,field):\n",
    "    results = []\n",
    "    conn = sqlite3.connect(DATABASE,timeout=10)\n",
    "    for row in conn.execute('SELECT * FROM {}'.format(table)):\n",
    "        results.append({'id':row[0],field:row[1]})\n",
    "    conn.close()\n",
    "    return results\n",
    "    \n",
    "def Flat_Dataframe(db):\n",
    "    DATABASE = db\n",
    "    query_pair_papers = \"\"\"\n",
    "    SELECT  ap.author_id,\n",
    "            a.author_name,\n",
    "            ap.paper_id,\n",
    "            p.paper_name\n",
    "    FROM author_paper AS ap\n",
    "    INNER JOIN author AS a ON ap.author_id = a.id\n",
    "    INNER JOIN paper AS p ON ap.paper_id = p.id\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DATABASE, timeout=10)\n",
    "    df = []\n",
    "    for row in conn.execute(query_pair_papers):\n",
    "        df.append(row)\n",
    "    conn.close()\n",
    "    df = pd.DataFrame(df,columns=['author_id','authors','paper_id','paper_name'])\n",
    "    return df\n",
    "\n",
    "def Generate_Edges_Authors(db):\n",
    "    DATABASE = db\n",
    "# Cria lista de arestas para rede de autores\n",
    "    query_pair_authors = \"\"\"\n",
    "    SELECT paper_id,\n",
    "           a1.author_id AS author1,\n",
    "           a2.author_id AS author2\n",
    "    FROM author_paper AS a1\n",
    "    JOIN author_paper AS a2 USING (paper_id)\n",
    "    WHERE a1.author_id < a2.author_id;\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DATABASE,timeout=10)\n",
    "    edges_authors = []\n",
    "    for row in conn.execute(query_pair_authors):\n",
    "        edges_authors.append(row)\n",
    "    conn.close()\n",
    "    edges_authors= pd.DataFrame(edges_authors,dtype=int,columns=['paper','author1',\n",
    "                                                                 'author2']).applymap(lambda x: int(x))\n",
    "    \n",
    "    count_authors = edges_authors.groupby(['author1','author2']).count().reset_index()\n",
    "    return count_authors\n",
    "\n",
    "\n",
    "def Generate_Edges_Papers(db):\n",
    "    DATABASE = db\n",
    "# Cria lista de arestas para rede de papers\n",
    "    query_pair_papers = \"\"\"\n",
    "    SELECT author_id,\n",
    "           a1.paper_id AS paper1,\n",
    "           a2.paper_id AS paper2\n",
    "    FROM author_paper AS a1\n",
    "    JOIN author_paper AS a2 USING (author_id)\n",
    "    WHERE a1.paper_id < a2.paper_id;\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DATABASE, timeout=10)\n",
    "    edges_papers = []\n",
    "    for row in conn.execute(query_pair_papers):\n",
    "        edges_papers.append(row)\n",
    "    conn.close()\n",
    "    edges_papers = pd.DataFrame(edges_papers,dtype = int,columns=['author',\n",
    "                                                      'paper1','paper2']).applymap(lambda x: int(x))\n",
    "    \n",
    "    count_papers  = edges_papers.groupby(['paper1','paper2']).count().reset_index()\n",
    "    \n",
    "    return count_papers\n",
    "    \n",
    "\n",
    "def Create_Network(nodes,edges,source='source', target='target',weight='weight'):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for d in nodes:\n",
    "        node_id = int(d['id'])\n",
    "        G.add_node(node_id, **d) \n",
    "    \n",
    "    for d in edges.to_dict('records'):\n",
    "        G.add_edge(d[source],d[target],count = d[weight])\n",
    "    \n",
    "    pos = nx.spring_layout(G)\n",
    "    pos = pd.DataFrame(pos).transpose()\n",
    "    \n",
    "    pos['id'] = pos.index\n",
    "    pos.columns = ['x','y','id']\n",
    "\n",
    "    \n",
    "    return (G, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors       = Select_All(DATABASE,table='author',field='author_name')\n",
    "papers        = Select_All(DATABASE,table='paper',field='paper_name')\n",
    "edges_authors = Generate_Edges_Authors(DATABASE) \n",
    "edges_papers  = Generate_Edges_Papers(DATABASE) \n",
    "df            = Flat_Dataframe(DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_authors, pos_authors = Create_Network(authors,edges_authors,'author1','author2','paper')\n",
    "G_papers, pos_papers   = Create_Network(papers,edges_papers,'paper1','paper2','author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3(datascience)",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
